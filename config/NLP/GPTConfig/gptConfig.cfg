# frontend.toml 配置文件

# openai配置
[openai]
# 你的 OpenAI API Key, 可以在 https://beta.openai.com/account/api-keys 获取
api_key = "sk-xxxxxx"

# azure配置（当你使用azure OpenAI的时候）
[azure]
end_point = "xxxxx"
api_key = "xxxxx"
deployment_id = "xxxxx"
api_version = "2023-05-15"
# 通用配置
[general]
# 使用的模型，默认是 gpt-3.5-turbo
model = "gpt-3.5-turbo"
# 对话温度，越大越随机 参照https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be
temperature = 0.3
#代替温度采样的方法，称为核采样。其中模型考虑具有top_p概率质量的标记的结果。所以0.1意味着只考虑构成前10%概率质量的标记。我们通常建议更改此值或对话温度，但不要同时更改两者。默认为1.
top_p = 1
# 每次对话最大生成使用token数量
max_tokens = 1000
# stop,不太明白
stop = ""
# -2.0和2.0之间的数字。正值会根据到目前为止是否出现在文本中来惩罚新标记，从而增加模型谈论新主题的可能性。默认为0。
presence_penalty = 0
# -2.0和2.0之间的数字。正值会根据新标记在文本中的现有频率对其进行惩罚，从而降低模型逐字重复同一行的可能性。默认为0。
frequency_penalty = 0

